{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f56e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreas/elec4630/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 187695104 bytes (21370244987 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/shreyansjain04/ai-vs-real-image-dataset?dataset_version_number=1 (187695104/21557940091) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3.53G/20.1G [02:33<12:37, 23.4MB/s] \n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkagglehub\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[43mkagglehub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_download\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshreyansjain04/ai-vs-real-image-dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m test_path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshreyansjain04/ai-vs-real-image-test-dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/kagglehub/datasets.py:43\u001b[0m, in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     41\u001b[0m h \u001b[38;5;241m=\u001b[39m parse_dataset_handle(handle)\n\u001b[1;32m     42\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading Dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;241m.\u001b[39mto_url()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m, extra\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mEXTRA_CONSOLE_BLOCK})\n\u001b[0;32m---> 43\u001b[0m path, _ \u001b[38;5;241m=\u001b[39m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/kagglehub/registry.py:28\u001b[0m, in \u001b[0;36mMultiImplRegistry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/kagglehub/resolver.py:29\u001b[0m, in \u001b[0;36mResolver.__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m, handle: T, path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, force_download: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     17\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Optional[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resolves a handle into a path with the requested file(s) and the resource's version number.\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m        Some cases where version number might be missing: Competition datasource, API-based models.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     path, version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     register_datasource_access(handle, version)\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/kagglehub/http_resolver.py:130\u001b[0m, in \u001b[0;36mDatasetHttpResolver._resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    127\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(archive_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# First, we download the archive.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marchive_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m _extract_archive(archive_path, out_path)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Delete the archive\u001b[39;00m\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/kagglehub/clients.py:214\u001b[0m, in \u001b[0;36mKaggleApiV1Client.download_file\u001b[0;34m(self, path, out_file, resource_handle, cached_path, extract_auto_compressed_file)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    207\u001b[0m         response\u001b[38;5;241m.\u001b[39murl,  \u001b[38;5;66;03m# URL after redirection\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    211\u001b[0m         headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize_read\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    212\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m resumed_response:\n\u001b[1;32m    213\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResuming download from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize_read\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) bytes left.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 214\u001b[0m         \u001b[43m_download_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresumed_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_read\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_object\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/kagglehub/clients.py:277\u001b[0m, in \u001b[0;36m_download_file\u001b[0;34m(response, out_file, size_read, total_size, hash_object)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(out_file, open_mode) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_content(CHUNK_SIZE):\n\u001b[0;32m--> 277\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hash_object:\n\u001b[1;32m    279\u001b[0m             hash_object\u001b[38;5;241m.\u001b[39mupdate(chunk)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "train_path = kagglehub.dataset_download(\"shreyansjain04/ai-vs-real-image-dataset\")\n",
    "\n",
    "test_path = kagglehub.dataset_download(\"shreyansjain04/ai-vs-real-image-test-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_ct_exact_fast(image, kernel_size=3, max_iter=10):\n",
    "    def em_channel(channel):\n",
    "        alpha = kernel_size // 2\n",
    "        padded = cv2.copyMakeBorder(channel, alpha, alpha, alpha, alpha, cv2.BORDER_REFLECT)\n",
    "        h, w = channel.shape\n",
    "        N = h * w\n",
    "        d = kernel_size**2 - 1\n",
    "\n",
    "        # Precompute patch offsets (excluding center)\n",
    "        patch_offsets = []\n",
    "        center = kernel_size // 2\n",
    "        for i in range(kernel_size):\n",
    "            for j in range(kernel_size):\n",
    "                if i == center and j == center:\n",
    "                    continue\n",
    "                patch_offsets.append((i - center, j - center))\n",
    "\n",
    "        A = np.zeros((N, d), dtype=np.float32)\n",
    "        b = np.zeros(N, dtype=np.float32)\n",
    "\n",
    "        idx = 0\n",
    "        for y in range(alpha, h + alpha):\n",
    "            for x in range(alpha, w + alpha):\n",
    "                A[idx] = [padded[y + dy, x + dx] for dy, dx in patch_offsets]\n",
    "                b[idx] = padded[y, x]\n",
    "                idx += 1\n",
    "\n",
    "        k = np.zeros(d, dtype=np.float32)\n",
    "        for _ in range(max_iter):\n",
    "            pred = A @ k\n",
    "            residuals = b - pred\n",
    "            sigma2 = np.mean(residuals**2)\n",
    "            weights = np.exp(-residuals**2 / (2 * sigma2))\n",
    "\n",
    "            # Use element-wise weighting instead of a full diagonal matrix\n",
    "            Aw = A * weights[:, np.newaxis]\n",
    "            bw = b * weights\n",
    "            k = np.linalg.pinv(A.T @ Aw) @ (A.T @ bw)\n",
    "\n",
    "        return k\n",
    "\n",
    "    if image.shape[2] != 3:\n",
    "        raise ValueError(\"Image must be RGB\")\n",
    "\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    return np.concatenate([em_channel(image[..., c]) for c in range(3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f07bbc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m\n\u001b[1;32m     23\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m dblock \u001b[38;5;241m=\u001b[39m DataBlock(\n\u001b[1;32m     26\u001b[0m     blocks\u001b[38;5;241m=\u001b[39m(ImageBlock, CategoryBlock),\n\u001b[1;32m     27\u001b[0m     get_items\u001b[38;5;241m=\u001b[39mpartial(get_balanced_subset, max_per_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m),\n\u001b[1;32m     28\u001b[0m     get_y\u001b[38;5;241m=\u001b[39mparent_label,\n\u001b[1;32m     29\u001b[0m     splitter\u001b[38;5;241m=\u001b[39mRandomSplitter(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m dls \u001b[38;5;241m=\u001b[39m \u001b[43mdblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# --- Extract CT Features and Labels ---\u001b[39;00m\n\u001b[1;32m     35\u001b[0m X, y \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastai/data/block.py:157\u001b[0m, in \u001b[0;36mDataBlock.dataloaders\u001b[0;34m(self, source, path, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdataloaders\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    152\u001b[0m     source, \u001b[38;5;66;03m# The data source\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     path:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Data source and default `Learner` path \u001b[39;00m\n\u001b[1;32m    154\u001b[0m     verbose:\u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# Show verbose messages\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    156\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataLoaders:\n\u001b[0;32m--> 157\u001b[0m     dsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m: verbose}\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dsets\u001b[38;5;241m.\u001b[39mdataloaders(path\u001b[38;5;241m=\u001b[39mpath, after_item\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tfms, after_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tfms, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastai/data/block.py:149\u001b[0m, in \u001b[0;36mDataBlock.datasets\u001b[0;34m(self, source, verbose)\u001b[0m\n\u001b[1;32m    147\u001b[0m splits \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplitter \u001b[38;5;129;01mor\u001b[39;00m RandomSplitter())(items)\n\u001b[1;32m    148\u001b[0m pv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(splits)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m datasets of sizes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(s))\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ms\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39msplits])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, verbose)\n\u001b[0;32m--> 149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDatasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_combine_type_tfms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdl_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_inp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastai/data/core.py:445\u001b[0m, in \u001b[0;36mDatasets.__init__\u001b[0;34m(self, items, tfms, tls, n_inp, dl_type, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    437\u001b[0m     items:\u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     tfms:MutableSequence\u001b[38;5;241m|\u001b[39mPipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    443\u001b[0m ):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dl_type\u001b[38;5;241m=\u001b[39mdl_type)\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls \u001b[38;5;241m=\u001b[39m L(tls \u001b[38;5;28;01mif\u001b[39;00m tls \u001b[38;5;28;01melse\u001b[39;00m [TfmdLists(items, t, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m L(ifnone(tfms,[\u001b[38;5;28;01mNone\u001b[39;00m]))])\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_inp \u001b[38;5;241m=\u001b[39m ifnone(n_inp, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastai/data/core.py:445\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    437\u001b[0m     items:\u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of items to create `Datasets`\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     tfms:MutableSequence\u001b[38;5;241m|\u001b[39mPipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;66;03m# List of `Transform`(s) or `Pipeline` to apply\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    443\u001b[0m ):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(dl_type\u001b[38;5;241m=\u001b[39mdl_type)\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls \u001b[38;5;241m=\u001b[39m L(tls \u001b[38;5;28;01mif\u001b[39;00m tls \u001b[38;5;28;01melse\u001b[39;00m [\u001b[43mTfmdLists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m L(ifnone(tfms,[\u001b[38;5;28;01mNone\u001b[39;00m]))])\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_inp \u001b[38;5;241m=\u001b[39m ifnone(n_inp, \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtls)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastcore/foundation.py:100\u001b[0m, in \u001b[0;36m_L_Meta.__call__\u001b[0;34m(cls, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x,\u001b[38;5;28mcls\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastai/data/core.py:359\u001b[0m, in \u001b[0;36mTfmdLists.__init__\u001b[0;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_setup:\n\u001b[1;32m    358\u001b[0m     pv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting up \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, verbose)\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_setup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_setup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/elec4630/.venv/lib/python3.10/site-packages/fastai/data/core.py:388\u001b[0m, in \u001b[0;36mTfmdLists.setup\u001b[0;34m(self, train_setup)\u001b[0m\n\u001b[1;32m    386\u001b[0m         x \u001b[38;5;241m=\u001b[39m f(x)\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(x))\n\u001b[0;32m--> 388\u001b[0m types \u001b[38;5;241m=\u001b[39m L(t \u001b[38;5;28;01mif\u001b[39;00m is_listy(t) \u001b[38;5;28;01melse\u001b[39;00m [t] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes)\u001b[38;5;241m.\u001b[39mconcat()\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretty_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from pathlib import Path\n",
    "\n",
    "def get_balanced_subset(path, max_per_class=500):\n",
    "    files = get_image_files(path)\n",
    "    grouped = {}\n",
    "    for f in files:\n",
    "        lbl = parent_label(f).lower()\n",
    "        grouped.setdefault(lbl, []).append(f)\n",
    "\n",
    "    selected = []\n",
    "    for lbl, f_list in grouped.items():\n",
    "        selected.extend(f_list[:max_per_class])\n",
    "    \n",
    "    return selected\n",
    "\n",
    "# --- Load Data using FastAI ---\n",
    "path = Path(\"data\")\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=partial(get_balanced_subset, max_per_class=500),\n",
    "    get_y=parent_label,\n",
    "    splitter=RandomSplitter(seed=42)\n",
    ")\n",
    "\n",
    "dls = dblock.dataloaders(path, bs=16)\n",
    "\n",
    "# --- Extract CT Features and Labels ---\n",
    "X, y = [], []\n",
    "for img, label in dls.train_ds:\n",
    "    ct_vec = extract_ct(img, kernel_size=3)\n",
    "    X.append(ct_vec)\n",
    "    y.append(int(label))\n",
    "\n",
    "X_valid, y_valid = [], []\n",
    "for img, label in dls.valid_ds:\n",
    "    ct_vec = extract_ct(img, kernel_size=3)\n",
    "    X_valid.append(ct_vec)\n",
    "    y_valid.append(int(label))\n",
    "\n",
    "# --- Train Random Forest ---\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# --- Evaluate ---\n",
    "y_pred = rf.predict(X_valid)\n",
    "print(classification_report(y_valid, y_pred, target_names=[\"ai\", \"real\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9332a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "def compare_ct_vectors(vec1, vec2, verbose=True):\n",
    "    \"\"\"\n",
    "    Compares two CT vectors using multiple similarity metrics.\n",
    "\n",
    "    Args:\n",
    "        vec1, vec2: numpy arrays of same shape\n",
    "        verbose: whether to print comparison scores\n",
    "\n",
    "    Returns:\n",
    "        dict of scores\n",
    "    \"\"\"\n",
    "    vec1 = np.array(vec1).reshape(1, -1)\n",
    "    vec2 = np.array(vec2).reshape(1, -1)\n",
    "\n",
    "    assert vec1.shape == vec2.shape, \"CT vectors must have the same shape\"\n",
    "\n",
    "    cosine_sim = cosine_similarity(vec1, vec2)[0][0]\n",
    "    euclid = euclidean(vec1[0], vec2[0])\n",
    "    corr, _ = pearsonr(vec1[0], vec2[0])\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"🔍 Cosine Similarity:     {cosine_sim:.4f}\")\n",
    "        print(f\"📏 Euclidean Distance:    {euclid:.4f}\")\n",
    "        print(f\"📈 Pearson Correlation:   {corr:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"cosine_similarity\": cosine_sim,\n",
    "        \"euclidean_distance\": euclid,\n",
    "        \"pearson_correlation\": corr\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"sml/real/6.jpg\")\n",
    "img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "img1 = cv2.resize(img1, (256, 256))\n",
    "\n",
    "img2 = cv2.imread(\"sml/ai/6.jpg\")\n",
    "img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.resize(img2, (256, 256))\n",
    "\n",
    "vec1 = extract_ct_exact(img1, kernel_size=3)\n",
    "vec2 = extract_ct_exact(img2, kernel_size=3)\n",
    "\n",
    "compare_ct_vectors(vec1, vec2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
